{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lffFsqA8BbFV",
        "outputId": "c0b2af38-16f0-4d12-8761-cb9a9397306c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.8.0 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.8.0\u001b[0m\u001b[31m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torchtext.legacy'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [4], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mpip\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minstall torch==1.8.0 torchtext==0.9.0\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchtext\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlegacy\u001b[39;00m \u001b[39mimport\u001b[39;00m data\n\u001b[1;32m      6\u001b[0m SEED \u001b[39m=\u001b[39m \u001b[39m1234\u001b[39m\n\u001b[1;32m      8\u001b[0m torch\u001b[39m.\u001b[39mmanual_seed(SEED)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchtext.legacy'"
          ]
        }
      ],
      "source": [
        "# %pip uninstall -y torchtext\n",
        "%pip install torch==1.8.0 torchtext==0.9.0\n",
        "import torch\n",
        "from torchtext.legacy import data\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data.Field(tokenize = 'spacy',\n",
        "                  tokenizer_language = 'en_core_web_sm')\n",
        "LABEL = data.LabelField(dtype = torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IatXWViqB3Pi",
        "outputId": "aeae9759-ab9b-4247-da84-3c0c837214e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:08<00:00, 9.73MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training examples: 25000\n",
            "Number of testing examples: 25000\n",
            "{'text': ['How', 'you', 'could', 'say', 'that', 'Peaches', ',', 'with', 'its', 'complex', 'narrative', 'dealing', 'with', 'a', 'multitude', 'of', 'issues', ',', 'is', '\"', 'a', 'small', 'TV', 'idea', '\"', 'is', 'beyond', 'me', '.', 'Besides', 'I', 'can', 'think', 'of', 'many', 'films', 'that', 'have', '\"', 'a', 'small', 'TV', 'idea', '\"', 'in', 'their', 'plots', '.', 'Your', 'obvious', 'dislike', 'of', 'the', 'TV', 'industry', '(', '\"', 'Sue', 'Smith', 'has', 'failed', 'to', 'rise', 'above', 'her', 'television', 'background', '\"', ')', 'is', 'confusing', '.', 'particularly', 'as', 'you', 'are', 'having', 'such', '\"', 'a', 'great', 'time', '\"', 'working', 'in', 'TV', '.', 'If', 'only', 'we', 'could', 'all', 'be', 'so', 'talented', 'as', 'Ms', 'Smith', '(', 'no', ',', 'I', 'am', 'not', 'a', 'friend', 'or', 'relative', ')', '-', 'AFI', 'award', 'winning', 'Brides', 'of', 'Christ', ',', 'Road', 'from', 'Coorain', ',', 'etc', '.', 'All', 'made', 'for', 'TV', '.', 'Come', 'to', 'think', 'of', 'it', ',', 'what', 'about', 'those', 'other', '\"', 'small', 'TV', 'ideas', '\"', 'like', '\"', 'Against', 'the', 'Wind', '\"', ',', '\"', 'Bodyline', '\"', ',', '\"', 'The', 'Dismissal', '\"', ',', '\"', 'Scales', 'of', 'Justice', '\"', ',', '\"', 'Blue', 'Murder', '\"', ',', '\"', 'Water', 'under', 'the', 'Bridge', '\"', ',', 'etc', '.', 'I', 'think', 'Peaches', 'is', 'a', 'good', 'entertaining', 'film', 'which', 'had', 'me', 'interested', ',', 'and', 'most', 'of', 'my', 'friends', 'as', 'well', ',', 'from', 'start', 'to', 'finish', '.', 'It', 'is', 'far', 'from', 'flawless', 'yet', 'I', 'think', 'it', 'is', 'among', 'the', 'best', 'Australian', 'films', 'I', 'have', 'seen', 'over', 'the', 'last', 'couple', 'of', 'years', '.', 'Who', 'knows', ',', 'with', 'a', 'few', 'more', 'viewings', '(', 'there', \"'s\", 'so', 'much', 'to', 'think', 'about', ')', ',', 'it', 'might', 'just', 'be', 'up', 'there', 'with', 'classics', 'like', '\"', 'The', 'Year', 'My', 'Voice', 'Broke', '\"', ',', '\"', 'The', 'Devil', \"'s\", 'Playground', '\"', '.', 'I', 'really', 'did', 'enjoy', 'this', 'film', 'much', 'more', 'than', '\"', 'Somersault', '\"', 'and', '\"', 'Three', 'Dollars', '\"', '.', 'These', 'films', ',', 'I', 'think', ',', 'had', 'their', 'moments', '-', 'surreal', ',', 'atmospheric', ',', 'realistic', 'and', 'dealing', 'with', 'important', 'contemporary', 'issues', ',', 'but', 'as', 'for', 'sheer', 'entertainment', 'for', 'mr.and', 'mrs', 'average', 'movie', 'goer', 'and', 'me', ',', 'it', 'was', 'very', 'ordinary', 'if', 'not', 'boring', '.', 'When', 'I', 'go', 'to', 'a', 'movie', ',', 'I', 'am', 'always', 'conscious', 'of', 'the', 'audience', \"'s\", 'reaction', 'to', 'a', 'film', '(', 'through', 'in-', 'cinemas', 'reactions', 'and', 'overheard', 'conversations', 'in', 'the', 'foyer', 'and', 'loo', ')', '.', 'Some', 'came', 'out', 'of', 'Peaches', 'shaking', 'their', 'heads', ',', 'some', 'with', 'negative', 'criticisms', ',', 'but', 'many', 'seemed', 'to', 'have', 'enjoyed', 'the', 'experience', '.'], 'label': 'pos'}\n"
          ]
        }
      ],
      "source": [
        "from torchtext.legacy import datasets\n",
        "\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')\n",
        "print(vars(train_data.examples[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RnxEJ0RB3-J",
        "outputId": "2d0fad6a-268a-4214-9fda-b9775b0cf044"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training examples: 17500\n",
            "Number of validation examples: 7500\n",
            "Number of testing examples: 25000\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(SEED))\n",
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtSufWSGB_bw",
        "outputId": "f0398076-fc18-45da-ac25-3884e55ecc88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 25002\n",
            "Unique tokens in LABEL vocabulary: 2\n",
            "[('the', 202564), (',', 192677), ('.', 165339), ('and', 109389), ('a', 109102), ('of', 100567), ('to', 93374), ('is', 76168), ('in', 61355), ('I', 54163), ('it', 53271), ('that', 49257), ('\"', 44157), (\"'s\", 43195), ('this', 42394), ('-', 37314), ('/><br', 35688), ('was', 35265), ('as', 30488), ('with', 30008)]\n",
            "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']\n",
            "defaultdict(None, {'neg': 0, 'pos': 1})\n"
          ]
        }
      ],
      "source": [
        "MAX_VOCAB_SIZE = 25_000\n",
        "\n",
        "TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
        "LABEL.build_vocab(train_data)\n",
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")\n",
        "print(TEXT.vocab.freqs.most_common(20))\n",
        "print(TEXT.vocab.itos[:10])\n",
        "print(LABEL.vocab.stoi)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# Do not use BucketIterator in your implementation because you are required to implement the padding and masking yourself.\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits((train_data, valid_data, test_data), batch_size=1, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nI_gFLUXCEdY"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "class LR(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        self.fc = nn.Linear(embedding_dim, output_dim)\n",
        "    def forward(self, text):\n",
        "        embedded = self.embedding(text).squeeze().sum(0)\n",
        "        return self.fc(embedded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lZ2obDVDmEl"
      },
      "outputs": [],
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "OUTPUT_DIM = 1\n",
        "\n",
        "model = LR(INPUT_DIM, EMBEDDING_DIM, OUTPUT_DIM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJ6_rLRuK2l7",
        "outputId": "ce464ac9-7c86-4b94-88ad-8e101c8f5892"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The model has 2,500,301 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbufnJzvLAlf"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1fHORT8LBOK"
      },
      "outputs": [],
      "source": [
        "criterion = nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3gdBHHULC7y"
      },
      "outputs": [],
      "source": [
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KF2EdETnLEwt"
      },
      "outputs": [],
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2o9l76H5LGm9"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for instance in tqdm(iterator, desc=\"Training...\", total=len(iterator)):\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "                \n",
        "        predictions = model(instance.text)\n",
        "        \n",
        "        loss = criterion(predictions, instance.label)\n",
        "        \n",
        "        acc = binary_accuracy(predictions, instance.label)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBwRhOrzLKSH"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for instance in tqdmiterator:\n",
        "\n",
        "            predictions = model(instance.text)\n",
        "            \n",
        "            loss = criterion(predictions, instance.label)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, instance.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOHkN5P5LMtl"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63EPftxxLOxH",
        "outputId": "c9b3ed74-e36e-4969-ea5d-476a6d7051cf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 17500/17500 [00:35<00:00, 491.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 41s\n",
            "\tTrain Loss: 12.071 | Train Acc: 62.04%\n",
            "\t Val. Loss: 9.109 |  Val. Acc: 62.08%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 17500/17500 [00:35<00:00, 494.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 02 | Epoch Time: 0m 40s\n",
            "\tTrain Loss: 8.050 | Train Acc: 65.55%\n",
            "\t Val. Loss: 5.415 |  Val. Acc: 68.56%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 17500/17500 [00:35<00:00, 493.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 03 | Epoch Time: 0m 41s\n",
            "\tTrain Loss: 6.874 | Train Acc: 67.21%\n",
            "\t Val. Loss: 6.106 |  Val. Acc: 68.64%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 17500/17500 [00:35<00:00, 492.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 04 | Epoch Time: 0m 41s\n",
            "\tTrain Loss: 6.504 | Train Acc: 69.42%\n",
            "\t Val. Loss: 8.343 |  Val. Acc: 64.91%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 17500/17500 [00:35<00:00, 493.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 05 | Epoch Time: 0m 41s\n",
            "\tTrain Loss: 5.884 | Train Acc: 70.01%\n",
            "\t Val. Loss: 5.660 |  Val. Acc: 71.72%\n"
          ]
        }
      ],
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2vQBjeTLTTv",
        "outputId": "e767d8c6-ce03-4e15-b0c3-60c6f851c349"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 5.609 | Test Acc: 67.24%\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('tut1-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ev4idwpONzs9",
        "outputId": "369fb192-fa2a-4b55-934f-7396f401efd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-6.7634], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([0.5967], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([5.0447], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([-0.4295], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([7.1855], device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Test of model correctness\n",
        "max_n_test_instances = 5\n",
        "i = 1\n",
        "for instance in valid_iterator:\n",
        "  score = model(instance.text)\n",
        "  print(score)\n",
        "  if i >= max_n_test_instances:\n",
        "    break\n",
        "  else:\n",
        "    i += 1\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pvenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8 (main, Oct 13 2022, 09:48:40) [Clang 14.0.0 (clang-1400.0.29.102)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "5b37beb76676c8b0643f5764b5c5ae0ddf876ecbab29b433e279cae2d82963c7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
